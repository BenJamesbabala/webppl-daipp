// run with: webppl examples/techreport/bayesnets/bn.wppl --require .


// ----------------------------------------------------------------------------

// Options

// Size of hidden layer for guide recognition net
var nHidden = 3;

// Number of training data points to draw from true distribution
var nTrainData = 100;

// Model learning
var doModelLearning = true;
// var modelLearnType = 'ML';
var modelLearnType = 'ML_reg';
// var modelLearnType = 'FullBayes';

// ----------------------------------------------------------------------------

// Creating global parameters
var makeMuGlobal = function(value) {
	return !doModelLearning ?
			value :
		modelLearnType === 'ML' ?
			paramScalar() :
		modelLearnType === 'ML_reg' ?
			sample(Gaussian({mu: 0, sigma: 1}), {
				guide: Delta({v: paramScalar()})
			}) :
		modelLearnType === 'FullBayes' ?
			sample(Gaussian({mu: 0, sigma: 1}), {
				guide: Gaussian({mu: paramScalar(), sigma: softplus(paramScalar())})
			}) :
		util.fatal('Unrecognized modelLearnType');
};
var makeSigmaGlobal = function(value) {
	return !doModelLearning ?
			value :
		modelLearnType === 'ML' ?
			softplus(paramScalar()) :
		modelLearnType === 'ML_reg' ?
			sample(Gamma({shape: 1, scale: 1}), {
				guide: Delta({v: softplus(paramScalar())})
			}) :
		modelLearnType === 'FullBayes' ?
			sample(Gamma({shape: 1, scale: 1}), {
				guide: Gamma({shape: softplus(paramScalar()), scale: softplus(paramScalar())})
			}) :
		util.fatal('Unrecognized modelLearnType');
};

// ----------------------------------------------------------------------------

// Different Bayes net topologies
var models = {

	// One continuous latent variable feeding into one continuous observed variable.
	oneLatent: {
		targetModel: function() {
			var a = sample(Gaussian({mu: 5, sigma: 1}));
			var b = sample(Gaussian({mu: a + 2, sigma: 0.5}));
			return {a: a, b: b};
		},
		model: function() {
			// Generative model params
			var mu_a = makeMuGlobal(5);
			var sigma_a = makeSigmaGlobal(1);

			// Guide params
			var params_a = perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});

			// Map over data
			var latents = mapData({data: globalStore.data}, function(datum) {

				// Guided sample the latent
				var inputs_a = Vector([standardize(datum.b, globalStore.moments.b)]);
				var outputs_a = perceptron(inputs_a, params_a);
				var gmu_a = T.get(outputs_a, 0);
				var gsigma_a = softplus(T.get(outputs_a, 1));
				var a = sample(Gaussian({mu: mu_a, sigma: sigma_a}), {
					guide: Gaussian({mu: gmu_a, sigma: gsigma_a})
				});

				// Observe datum
				observe(Gaussian({mu: a + 2, sigma: 0.5}), datum.b);

				// Return latents
				return {a: a};
			});

			// Return global params + latents
			return {
				params: { mu_a: mu_a, sigma_a: sigma_a },
				latents: latents
			};
		}
	},

	// Two continuous latent variables feeding into one continuous observed variable
	// Guide predicts latents independently
	twoLatents_indep: {
		targetModel: function() {
			var a = sample(Gaussian({mu: 1, sigma: 1}));
			var b = sample(Gaussian({mu: 5, sigma: 1}));
			var c = sample(Gaussian({mu: a + b, sigma: 0.5}));
			return {a: a, b: b, c: c};
		},
		model: function() {
			// Generative model params;
			var mu_a = makeMuGlobal(1);
			var sigma_a = makeSigmaGlobal(1);
			var mu_b = makeMuGlobal(5);
			var sigma_b = makeSigmaGlobal(1);

			// Guide params
			var params_a = perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});
			var params_b = perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});

			// Map over data
			var latents = mapData({data: globalStore.data}, function(datum) {

				var inputs_a = Vector([standardize(datum.c, globalStore.moments.c)]);
				var outputs_a = perceptron(inputs_a, params_a);
				var gmu_a = T.get(outputs_a, 0);
				var gsigma_a = softplus(T.get(outputs_a, 1));
				var a = sample(Gaussian({mu: mu_a, sigma: sigma_a}), {
					guide: Gaussian({mu: gmu_a, sigma: gsigma_a})
				});

				var inputs_b = inputs_a;
				var outputs_b = perceptron(inputs_b, params_b);
				var gmu_b = T.get(outputs_b, 0);
				var gsigma_b = softplus(T.get(outputs_b, 1));
				var b = sample(Gaussian({mu: mu_b, sigma: sigma_b}), {
					guide: Gaussian({mu: gmu_b, sigma: gsigma_b})
				});

				// Observe datum
				observe(Gaussian({mu: a + b, sigma: 0.5}), datum.c);

				// Return latents
				return {a: a, b: b};
			});
			
			// Return global params + latents
			return {
				params: { mu_a: mu_a, sigma_a: sigma_a, mu_b: mu_b, sigma_b: sigma_b },
				latents: latents
			};
		}	
	},

	// Two continuous latent variables feeding into one continuous observed variable
	// Second latent is predicted as a function of the first
	twoLatents_dep: {
		targetModel: function() {
			var a = sample(Gaussian({mu: 1, sigma: 1}));
			var b = sample(Gaussian({mu: 5, sigma: 1}));
			var c = sample(Gaussian({mu: a + b, sigma: 0.5}));
			return {a: a, b: b, c: c};
		},
		model: function() {
			// Generative model params;
			var mu_a = makeMuGlobal(1);
			var sigma_a = makeSigmaGlobal(1);
			var mu_b = makeMuGlobal(5);
			var sigma_b = makeSigmaGlobal(1);

			// Guide params
			var params_a = perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});
			var params_b = perceptronParams({nIn: 2, nHidden: nHidden, nOut: 2});

			// Map over data
			var latents = mapData({data: globalStore.data}, function(datum) {

				var inputs_a = Vector([standardize(datum.c, globalStore.moments.c)]);
				var outputs_a = perceptron(inputs_a, params_a);
				var gmu_a = T.get(outputs_a, 0);
				var gsigma_a = softplus(T.get(outputs_a, 1));
				var a = sample(Gaussian({mu: mu_a, sigma: sigma_a}), {
					guide: Gaussian({mu: gmu_a, sigma: gsigma_a})
				});

				var inputs_b = Vector([T.get(inputs_a, 0), standardize(a, globalStore.moments.a)]);
				var outputs_b = perceptron(inputs_b, params_b);
				var gmu_b = T.get(outputs_b, 0);
				var gsigma_b = softplus(T.get(outputs_b, 1));
				var b = sample(Gaussian({mu: mu_b, sigma: sigma_b}), {
					guide: Gaussian({mu: gmu_b, sigma: gsigma_b})
				});

				// Observe datum
				observe(Gaussian({mu: a + b, sigma: 0.5}), datum.c);

				// Return latents
				return {a: a, b: b};
			});
			
			// Return global params + latents
			return {
				params: { mu_a: mu_a, sigma_a: sigma_a, mu_b: mu_b, sigma_b: sigma_b },
				latents: latents
			};
		}	
	}
};

// ----------------------------------------------------------------------------

// Select which model to run
var whichModel = 'oneLatent';
// var whichModel = 'twoLatents_indep';
// var whichModel = 'twoLatents_dep';
var model = models[whichModel];


// Generate data from true distribution
var trainingData = repeat(nTrainData, model.targetModel);
globalStore.data = trainingData;

// Compute moments for standardization
globalStore.moments = mapObject(function(varname, varval) {
	var vals = map(function(x) { return x[varname]; }, globalStore.data);
	var mu = mean(vals);
	var sigma = stddev(vals, mu);
	return {mu: mu, sigma: sigma};
}, globalStore.data[0]);

// Optimize parameters
var params = Optimize(model.model, {
	steps: 500,
	optMethod: { adam: { stepSize: 0.1 } },
	estimator: { ELBO2: { samples: 1 } },
	verbose: true,
	logProgress: 'examples/techreport/bayesnets/elbo_progress.csv'
});

// ----------------------------------------------------------------------------

// Simple, 'eyeball' evaluations

display('');

// Compute expected value of params
var paramExpectations = function() {
	globalStore.data = [trainingData[0]];
	var post = SampleGuide(model.model, {params: params, samples: 100});
	var paramExample = sample(post).params;
	return mapObject(function(name, val) {
		return expectation(post, function(ret) {
			return ad.value(ret.params[name]);
		});
	}, paramExample);
};

// Compute expected value of latents for given observations
var latentExpectations = function(observations) {
	globalStore.data = [observations];
	var post = SampleGuide(model.model, {params: params, samples: 100});
	var latentExample = sample(post).latents[0];
	return mapObject(function(name, val) {
		return expectation(post, function(ret) {
			return ret.latents[0][name];
		});
	}, latentExample)
};

// Compare param expectations and latent expectations to true values
// TODO: Also compare to expectations computed via MCMC?
if (doModelLearning) {
	var prmEx = paramExpectations();
	display('Inferred expectation of params: ' + JSON.stringify(prmEx));
}
map(function(testDatum) {
	var latEx = latentExpectations(testDatum);
	display('True datum: ' + JSON.stringify(testDatum) +
		' | Inferred expectation of latents: ' + JSON.stringify(latEx));
}, repeat(10, model.targetModel));
undefined;

// ----------------------------------------------------------------------------

// More formal evaluations
// (ELBO progress is already saved )

display('');

// (Only if model learning) probability of data under learned model
if (doModelLearning) {
	var logZ = ForwardSample(model.model, {guide: true, params: params, samples: 1000}).normalizationConstant;
	display('Log probability of data under model: ' + logZ);
}

// (Only if not model learning?) ESS of guide as importance sampler
var testData = repeat(nTrainData, model.targetModel);
globalStore.data = testData;
var nEvalSamps = 100;
var ess = EvaluateGuide(model.model, {samples: nEvalSamps, params: params});
display('ESS % for recognition model: ' + (ess / nEvalSamps));


