// run with: webppl examples/techreport/bayesnets/bn.wppl --require .


// ----------------------------------------------------------------------------

// Options

// Size of hidden layer for guide recognition net
var nHidden = 3;

// Number of training data points to draw from true distribution
var nTrainData = 100;

// Model learning
var doModelLearning = true;
// var modelLearnType = 'ML';
var modelLearnType = 'ML_reg';
// var modelLearnType = 'MeanField';

// Local guide
// var localGuideType = 'MeanField';
var localGuideType = 'Recognition';

// ----------------------------------------------------------------------------

// Creating global parameters
var makeMuGlobal = function(value) {
	return !doModelLearning ?
			value :
		modelLearnType === 'ML' ?
			paramScalar() :
		modelLearnType === 'ML_reg' ?
			sample(Gaussian({mu: 0, sigma: 1}), {
				guide: Delta({v: paramScalar()})
			}) :
		modelLearnType === 'MeanField' ?
			sample(Gaussian({mu: 0, sigma: 1}), {
				guide: Gaussian({mu: paramScalar(), sigma: softplus(paramScalar())})
			}) :
		util.fatal('Unrecognized modelLearnType');
};
var makeSigmaGlobal = function(value) {
	return !doModelLearning ?
			value :
		modelLearnType === 'ML' ?
			softplus(paramScalar()) :
		modelLearnType === 'ML_reg' ?
			sample(Gamma({shape: 1, scale: 1}), {
				guide: Delta({v: softplus(paramScalar())})
			}) :
		modelLearnType === 'MeanField' ?
			sample(Gamma({shape: 1, scale: 1}), {
				guide: Gamma({shape: softplus(paramScalar()), scale: softplus(paramScalar())})
			}) :
		util.fatal('Unrecognized modelLearnType');
};
var makeWeightsGlobal = function(ws) {
	var n = ws.length; 

	var ones = function() { return Vector(repeat(n, function() { return 1; })); };

	return !doModelLearning ?
		Vector(ws) :
	modelLearnType === 'ML' ?
		simplex(paramVector(n-1)) :
	modelLearnType === 'ML_reg' ?
		sample(Dirichlet({alpha: ones()}), {
			guide: Delta({v: simplex(paramVector(n-1))})
		}) :
	modelLearnType === 'MeanField' ?
		sample(Dirichlet({alpha: ones()}), {
			guide: LogisticNormal({mu: paramVector(n-1), sigma: softplus(paramVector(n-1))})
		}) :
	util.fatal('Unrecognized modelLearnType');
};

// Local mean field guides
var gaussianMeanFieldParams = function() {
	return {mu: paramScalar(), sigma: softplus(paramScalar())};
};
var discreteMeanFieldParams = function(n) {
	return simplex(paramVector(n-1));
};

// ----------------------------------------------------------------------------

// Different Bayes net topologies
var models = {

	// One continuous latent variable feeding into one continuous observed variable.
	oneLatent: {
		targetModel: function() {
			var a = sample(Gaussian({mu: 5, sigma: 1}));
			var b = sample(Gaussian({mu: a + 2, sigma: 0.5}));
			return {a: a, b: b};
		},
		model: function() {
			// Generative model params
			var mu_a = makeMuGlobal(5);
			var sigma_a = makeSigmaGlobal(1);

			// Guide params
			var nnparams_a = localGuideType === 'MeanField' ? null :
				perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});

			// Map over data
			var latents = mapData({data: globalStore.data}, function(datum) {

				// Compute guide params for latent a
				var gparams_a = localGuideType === 'MeanField' ? gaussianMeanFieldParams() : (function() {
					var inputs = Vector([standardize(datum.b, globalStore.moments.b)]);
					var outputs = perceptron(inputs, nnparams_a);
					return {mu: T.get(outputs, 0), sigma: softplus(T.get(outputs, 1))};
				})();

				// Guided sample the latent a
				var a = sample(Gaussian({mu: mu_a, sigma: sigma_a}), {
					guide: Gaussian(gparams_a)
				});

				// Observe datum
				observe(Gaussian({mu: a + 2, sigma: 0.5}), datum.b);

				// Return latents
				return {a: a};
			});

			// Return global params + latents
			return {
				params: { mu_a: mu_a, sigma_a: sigma_a },
				latents: latents
			};
		}
	},

	// Two continuous latent variables feeding into one continuous observed variable
	// Guide predicts latents independently
	twoLatents_indep: {
		targetModel: function() {
			var a = sample(Gaussian({mu: 1, sigma: 1}));
			var b = sample(Gaussian({mu: 5, sigma: 1}));
			var c = sample(Gaussian({mu: a + b, sigma: 0.5}));
			return {a: a, b: b, c: c};
		},
		model: function() {
			// Generative model params;
			var mu_a = makeMuGlobal(1);
			var sigma_a = makeSigmaGlobal(1);
			var mu_b = makeMuGlobal(5);
			var sigma_b = makeSigmaGlobal(1);

			// Guide params
			var nnparams_a = localGuideType === 'MeanField' ? null :
				perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});
			var nnparams_b = localGuideType === 'MeanField' ? null :
				perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});

			// Map over data
			var latents = mapData({data: globalStore.data}, function(datum) {

				// Compute guide params for latent a
				var gparams_a = localGuideType === 'MeanField' ? gaussianMeanFieldParams() : (function() {
					var inputs = Vector([standardize(datum.c, globalStore.moments.c)]);
					var outputs = perceptron(inputs, nnparams_a);
					return {mu: T.get(outputs, 0), sigma: softplus(T.get(outputs, 1))};
				})();
				// Guided sample latent a
				var a = sample(Gaussian({mu: mu_a, sigma: sigma_a}), {
					guide: Gaussian(gparams_a)
				});

				// Compute guide params for latent b
				var gparams_b = localGuideType === 'MeanField' ? gaussianMeanFieldParams() : (function() {
					var inputs = Vector([standardize(datum.c, globalStore.moments.c)]);
					var outputs = perceptron(inputs, nnparams_b);
					return {mu: T.get(outputs, 0), sigma: softplus(T.get(outputs, 1))};
				})();
				// Guided sample latent b
				var b = sample(Gaussian({mu: mu_b, sigma: sigma_b}), {
					guide: Gaussian(gparams_b)
				});

				// Observe datum
				observe(Gaussian({mu: a + b, sigma: 0.5}), datum.c);

				// Return latents
				return {a: a, b: b};
			});
			
			// Return global params + latents
			return {
				params: { mu_a: mu_a, sigma_a: sigma_a, mu_b: mu_b, sigma_b: sigma_b },
				latents: latents
			};
		}	
	},

	// Two continuous latent variables feeding into one continuous observed variable
	// Second latent is predicted as a function of the first
	twoLatents_dep: {
		targetModel: function() {
			var a = sample(Gaussian({mu: 1, sigma: 1}));
			var b = sample(Gaussian({mu: 5, sigma: 1}));
			var c = sample(Gaussian({mu: a + b, sigma: 0.5}));
			return {a: a, b: b, c: c};
		},
		model: function() {
			// Generative model params;
			var mu_a = makeMuGlobal(1);
			var sigma_a = makeSigmaGlobal(1);
			var mu_b = makeMuGlobal(5);
			var sigma_b = makeSigmaGlobal(1);

			// Guide params
			var nnparams_a = localGuideType === 'MeanField' ? null :
				perceptronParams({nIn: 1, nHidden: nHidden, nOut: 2});
			var nnparams_b = localGuideType === 'MeanField' ? null :
				perceptronParams({nIn: 2, nHidden: nHidden, nOut: 2});

			// Map over data
			var latents = mapData({data: globalStore.data}, function(datum) {

				// Compute guide params for latent a
				var gparams_a = localGuideType === 'MeanField' ? gaussianMeanFieldParams() : (function() {
					var inputs = Vector([standardize(datum.c, globalStore.moments.c)]);
					var outputs = perceptron(inputs, nnparams_a);
					return {mu: T.get(outputs, 0), sigma: softplus(T.get(outputs, 1))};
				})();
				// Guided sample latent a
				var a = sample(Gaussian({mu: mu_a, sigma: sigma_a}), {
					guide: Gaussian(gparams_a)
				});

				// Compute guide params for latent b
				var gparams_b = localGuideType === 'MeanField' ? gaussianMeanFieldParams() : (function() {
					var inputs = Vector([standardize(datum.c, globalStore.moments.c),
										 standardize(a, globalStore.moments.a)]);
					var outputs = perceptron(inputs, nnparams_b);
					return {mu: T.get(outputs, 0), sigma: softplus(T.get(outputs, 1))};
				})();
				// Guided sample latent b
				var b = sample(Gaussian({mu: mu_b, sigma: sigma_b}), {
					guide: Gaussian(gparams_b)
				});

				// Observe datum
				observe(Gaussian({mu: a + b, sigma: 0.5}), datum.c);

				// Return latents
				return {a: a, b: b};
			});
			
			// Return global params + latents
			return {
				params: { mu_a: mu_a, sigma_a: sigma_a, mu_b: mu_b, sigma_b: sigma_b },
				latents: latents
			};
		}	
	},

	// Gaussian mixture model: one discrete latent feeding into one continuous observed variable
	gmm:  {
		targetModel: function() {
			var gaussParams = [
				{mu: 0, sigma: 2},
				{mu: -3, sigma: 0.5},
				{mu: 2, sigma: 1}
			];
			var i = sample(Discrete({ps: [0.1, 0.6, 0.3]}));
			var a = sample(Gaussian(gaussParams[i]));
			return {i: i, a: a};
		},
		model: function() {
			// Generative model params
			var weights = makeWeightsGlobal([0.1, 0.6, 0.3]);
			var gaussParams = [
				{mu: makeMuGlobal(0), sigma: makeSigmaGlobal(2)},
				{mu: makeMuGlobal(-3), sigma: makeSigmaGlobal(0.5)},
				{mu: makeMuGlobal(2), sigma: makeSigmaGlobal(1)}
			];

			// Guide params
			var nnparams_i = localGuideType === 'MeanField' ? null :
				perceptronParams({nIn: 1, nHidden: nHidden, nOut: gaussParams.length-1});

			// Map over data
			var latents = mapData({data: globalStore.data}, function(datum) {

				// Compute guide params for latent i
				var gparams_i = localGuideType === 'MeanField' ? discreteMeanFieldParams(gaussParams.length) : 
				(function() {
					var inputs = Vector([standardize(datum.a, globalStore.moments.a)]);
					var outputs = perceptron(inputs, nnparams_i);
					return simplex(outputs);
				})();
				// Sample latent i
				var i = sample(Discrete({ps: weights}), {
					guide: Discrete({ps: gparams_i})
				});

				// Observe datum
				observe(Gaussian(gaussParams[i]), datum.a);

				// Return latents
				return {i: i}
			});

			// Return global params + latents
			return {
				params: {weights: weights, gaussParams: gaussParams},
				latents: latents
			};
		}
	}
};

// ----------------------------------------------------------------------------

// Select which model to run
// var whichModel = 'oneLatent';
// var whichModel = 'twoLatents_indep';
// var whichModel = 'twoLatents_dep';
var whichModel = 'gmm';
var model = models[whichModel];


// Generate data from true distribution
var trainingData = repeat(nTrainData, model.targetModel);
globalStore.data = trainingData;

// Compute moments for standardization
globalStore.moments = mapObject(function(varname, varval) {
	var vals = map(function(x) { return x[varname]; }, globalStore.data);
	var mu = mean(vals);
	var sigma = stddev(vals, mu);
	return {mu: mu, sigma: sigma};
}, globalStore.data[0]);

// Optimize parameters
var params = Optimize(model.model, {
	steps: 500,
	optMethod: { adam: { stepSize: 0.1 } },
	estimator: { ELBO2: { samples: 1 } },
	verbose: true,
	logProgress: 'examples/techreport/bayesnets/elbo_progress.csv'
});

// ----------------------------------------------------------------------------

// Simple, 'eyeball' evaluations

display('');

// Compute expected value of params
var paramExpectations = function() {
	globalStore.data = [trainingData[0]];
	var post = SampleGuide(model.model, {params: params, samples: 100});
	var paramExample = sample(post).params;
	return mapObject(function(name, val) {
		return expectation(post, function(ret) {
			return ad.value(ret.params[name]);
		});
	}, paramExample);
};

// Compute expected value of latents for given observations
var latentExpectations = function(observations) {
	globalStore.data = [observations];
	var post = SampleGuide(model.model, {params: params, samples: 100});
	var latentExample = sample(post).latents[0];
	return mapObject(function(name, val) {
		return expectation(post, function(ret) {
			return ret.latents[0][name];
		});
	}, latentExample)
};

// Compare param expectations and latent expectations to true values
// TODO: Also compare to expectations computed via MCMC?
if (doModelLearning) {
	var prmEx = paramExpectations();
	display('Inferred expectation of params: ' + JSON.stringify(prmEx));
}
map(function(testDatum) {
	var latEx = latentExpectations(testDatum);
	display('True datum: ' + JSON.stringify(testDatum) +
		' | Inferred expectation of latents: ' + JSON.stringify(latEx));
}, repeat(10, model.targetModel));
undefined;

// ----------------------------------------------------------------------------

// More formal evaluations
// (ELBO progress is already saved )

display('');

// (Only if model learning) probability of data under learned model
if (doModelLearning) {
	var logZ = ForwardSample(model.model, {guide: true, params: params, samples: 1000}).normalizationConstant;
	display('Log probability of data under model: ' + logZ);
}

// (Only if not model learning?) ESS of guide as importance sampler
var nEvalData = 100;
var ess_estimates = repeat(nEvalData, function() {
	var testData = repeat(1, model.targetModel);
	globalStore.data = testData;
	var nEvalParticles = 100;
	var ess = EvaluateGuide(model.model, {samples: nEvalParticles, params: params});
	return (ess / nEvalParticles);
});
var avgESS = sum(ess_estimates) / nEvalData;
display('Average ESS % for recognition model: ' + avgESS);


