// Latent Dirichlet Allocation
// (enumerate out choice of topic per word)

// dritchie: Idk how to write a good manual guide for this, so I'm assuming that we're just going
//    to do either mean field or full auto DAIPP with this one...

assert(opts.doModelLearning);

var nHidden = opts.nHidden || 3;

var trainingData = readJSON('examples/data/bars2.json');
var vocabSize = 4;
var numTopics = 4;


// Parameter for prior on word distributions per topic.
var eta = Vector(repeat(vocabSize, constF(0.1)));
// Parameter for prior on topic distributions per document.
var alpha = Vector(repeat(numTopics, constF(0.1)));


var model = function() {
	// Top-level parameters
	var wordDistsForTopics = repeat(numTopics, function() {
		return Discrete({ps: makeWeightsGlobal(undefined, eta)});
	});

	// Map over documents
	mapData({data: globalStore.data, batchSize: opts.batchSize}, function(doc) {

		// TODO: Add auto guide
		var topicDistForDoc = Discrete({ps: makeWeightsGlobal(undefined, alpha)});

		mapIndexed(function(word, count) {

			if (count > 0) {
				// TODO: Add auto guide?
				var wordMarginalDist = Enumerate(function() {
					var topic = sample(topicDistForDoc);
					var wordDistForTopic = wordDistsForTopics[topic];
					return sample(wordDistForTopic);
				});
				factor(count * wordMarginalDist.score(word));
			}

		}, doc);

	});
};

