/*
WebPPL functions to manage the context and prediction networks.

These should be used to annotate the target program as so:
  Insert an initContext at start of thunk to initialize.
  Insert updateContext after each sample statement.
  Optional to do updateContext at other places (after primitives, fn returns).
  At sample statements guide as so: `sample(origDist, {guide: DAIPPguide(origDist, origDistParams)})`.
This file provides a simple helper function sampleDaipp that replaces sample and expands to the
  right guide+update code for known distributions.
  It should be possible for the daipp package to provide a macro that replaces sample with sampleDaipp and
  inserts initContext at the start of the model fn.

Two key helper functions are in a corresponding DAIPP.js file:
daipp.val2vec embeds js objects into vectors,
daipp.vec2dist chooses an importance distribution ad generates its params.
*/

var daippZeroVec = zeros([daipp.latentSize]);

// We may want to split the address into an array (of syntax sites);
// in that case val2vec will use an RNN along the array, making
// related addresses have related vectors.
var embedAddress = daipp.config.splitAddresses ?
    function(address) { return daipp.val2vec(daipp.util.splitAddress(address)); } :
    function(address) { return daipp.val2vec(address); };

//A function used to initialize the context, given some data (or a summary of data)
// dritchie: It's not clear to me why we really need another net here? Why not let the initial
//    context be the output of val2vec?
var initNet = nn.mlp(daipp.latentSize, [
  {nOut: daipp.latentSize, activation: nn.tanh},
  {nOut: daipp.latentSize}
], 'initNet', daipp.debug);
initNet.setTraining(true)
var initContext = function(data) {
  var dataVec = daipp.val2vec(data)

  var context = daipp.nneval(initNet, dataVec);

  globalStore.context = context

  return
}

//A function used to update the context upon getting a sampled (or deterministic) value
//TODO: make deeper? use GRU / LSTM? ResNet?
//TODO: take optional name/type to allow different update nets, eg for sample vs deterministic vs return.

var updateNet = daipp.makeUpdateNet(daipp.config, 'updateNet');

var updateContext = function(val) {
  var dataVec = daipp.val2vec(val)
  var address = getObsFnAddress()
  var addressVec = embedAddress(address);
  var context = globalStore.context

  var newContext = daipp.nneval(updateNet, [context, dataVec, addressVec]);
  globalStore.context = newContext

  return
}

//A function to predict the params of the importance distribution at a sample statement.

// `dist` is the distribution we're guiding.
// `val` will usually (by default) be the original params of dist, but
// we want to maintain the flexibility to put in other info.

// paul, paraphrasing noah:
// when `val` is the original dist params, we want to treat them as a
// tensor (so that they get minimally mangled).... simplest is
// probably just to upgrade them to tensor in the webppl program
// before calling DAIPPguide. so something like: `DAIPPguide(dist,
// ad.tensor(params))`.

// paul: note that params isn't necessarily an array of reals.

var predictNet = daipp.makeRU('rnn', daipp.latentSize, 2*daipp.latentSize, 'predictNet', daipp.debug);

var DAIPPguide = function(dist, val) {
  var address = getObsFnAddress()

  var dataVec = daipp.config.predictUsingVal ? daipp.val2vec(val) : daippZeroVec;
  var addressVec = daipp.config.predictUsingAddress ? embedAddress(address) : daippZeroVec;
  var context = daipp.config.predictUsingContext ? globalStore.context : daippZeroVec;

  //merge the val, address together
  var predictInput = ad.tensor.concat(addressVec, dataVec);
  var predict = daipp.nneval(predictNet, [context, predictInput]);

  //generate params as appropriate to dist
  var guide = daipp.vec2dist(predict, dist)
  // display(guide)
  return guide
}

//this helper samples from the guide and updates the context. except when opt.observedVal is defined it instead is a factor enforcing the observation.
var sampleDaipp = function(dist,opt) {
  //FIXME: in fantasy mode for sleepey phase, we want to sample even for observed vals? or just make sure they are undefined in that context?
  if(opt === undefined || opt.observedVal === undefined) {
    // Convert the dist params to an array to retain the behavior we
    // had under the old ERP interface. Probably better to have some
    // handling of this directly in val2vec at some point.
    var params = daipp.util.orderedValues(dist.params);
    var val = sample(dist, {guide: DAIPPguide(dist, params)})
    updateContext(val)
    return val
  } else {
    var val = opt.observedVal
    factor(dist.score(val))
    return val
  }
}

// Version of nneval appropriate for use as part of a generative model
var nnevalModel = function(nn, arg) {
  if (nn.getParameters().length > 0) {
    var params = daipp.nnparams(nn);
    // make the parameters part of the guide by sampling from
    //   and improper prior with a Delta guide.
    var gparams = map(function(p) {
      return sample(ImproperUniform(), {
        guide: Delta({v: p})
      });
    }, params);
    nn.setParameters(gparams);
  }
  return nn.eval(arg);
}


